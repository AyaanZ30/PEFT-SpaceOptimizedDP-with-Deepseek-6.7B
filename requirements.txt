# Core Hugging Face Libraries
transformers>=4.38.0
peft>=0.9.0
accelerate>=0.27.0
trl>=0.8.0
datasets>=2.17.0

# QLoRA Dependencies
bitsandbytes>=0.42.0

# Numerical/Utility Libraries
torch>=2.1
scipy>=1.11.4
psutil>=5.9.8

# Optional: To install flash-attn for better performance (requires specific GPU architecture)
# flash-attn>=2.5.5

# Note: The 'huggingface-hub' library is implicitly required for login and model downloads.